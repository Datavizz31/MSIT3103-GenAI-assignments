{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd2c993-aef2-4239-952a-44064dd6c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "ENV = {\n",
    "    \"HF_MODEL_ID\": \"gpt2\",\n",
    "    \"HF_TASK\": \"text-generation\",\n",
    "}\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    env=ENV, role=role,\n",
    "    transformers_version=\"4.49.0\", pytorch_version=\"2.6.0\", py_version=\"py312\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02c2bfd-fd43-48a6-9743-2d0fb75d3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to deploy the model\n",
      "------!model has been deployed\n"
     ]
    }
   ],
   "source": [
    "print(\"starting to deploy the model\")\n",
    "ENDPOINT_NAME = \"genai-gpt2-api\"\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=ENDPOINT_NAME)\n",
    "print(\"model has been deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a414ca1-c616-4b6d-9ab2-8622aa38eb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The future of artificial intelligence is very bright and we are looking at a time when it\\'s more likely that the next generation will be able to tackle some major problems such as climate change, diseases like AIDS and cancer.\\n\"It would seem quite an extraordinary idea for AI,\" he said. \"If you can\\'t get people involved in science then maybe there isn\\'n going any sense.\"'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\n",
    "  \"inputs\": \"The future of artificial intelligence is\",\n",
    "  \"parameters\": {\n",
    "    \"max_new_tokens\": 80,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"repetition_penalty\": 1.1\n",
    "  }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22dbbb11-173a-4e99-a8de-ac89d60b22a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"count\": 10,\n",
      "  \"p50_ms\": 2643.0187225341797,\n",
      "  \"p95_ms\": 2687.7570152282715,\n",
      "  \"avg_ms\": 2648.7853288650513\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time, json, statistics, boto3\n",
    "smrt = boto3.client(\"sagemaker-runtime\")\n",
    "PROMPT = \"Hello, today I want to talk about\"\n",
    "PARAMS = {\"max_new_tokens\": 50, \"temperature\": 0.7, \"top_p\": 0.9, \"do_sample\": True}\n",
    "\n",
    "def once():\n",
    "    t0 = time.time()\n",
    "    r = smrt.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps({\"inputs\": PROMPT, \"parameters\": PARAMS})\n",
    "    )\n",
    "    _ = r[\"Body\"].read()\n",
    "    return (time.time() - t0) * 1000.0\n",
    "\n",
    "# warmup\n",
    "for _ in range(3): once()\n",
    "\n",
    "N = 10\n",
    "times = sorted(once() for _ in range(N))\n",
    "print(json.dumps({\n",
    "    \"count\": N,\n",
    "    \"p50_ms\": times[N//2],\n",
    "    \"p95_ms\": times[int(0.95*N)-1],\n",
    "    \"avg_ms\": sum(times)/N\n",
    "}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bac8555-5dea-4490-9c85-c3d906c49644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: genai-gpt2-api genai-gpt2-api\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "ep = \"genai-gpt2-api\"\n",
    "cfg = sm.describe_endpoint(EndpointName=ep)[\"EndpointConfigName\"]\n",
    "sm.delete_endpoint(EndpointName=ep)\n",
    "sm.delete_endpoint_config(EndpointConfigName=cfg)\n",
    "print(\"Deleted:\", ep, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88a2fb-1e51-4e08-8945-ddbfcfc95036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
